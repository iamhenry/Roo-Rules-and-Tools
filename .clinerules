==========================
# Tools
==========================



<DebugError>
   1. explain
   2. debate concisely
   3. reflect
   4. fix using kiss & dry princples
</DebugError>

<ProposeSolution>
  1. Dont write any code.
  2. Clearly Define the Problem/Feature.
  3. List specific, verifiable assumptions.
  4. List acceptance criteria
  5. List affected files and sub files using tools to identify indirect impacts.
  6. Does this create or reduce technical debt?
  7. Propose a range of potential solutions
  8. Solution Comparison:
     - Create a table comparing solutions based on:
       - Pros and cons
       - Adherence to KISS, DRY, YAGNI.
       - Performance implications
       - Scalability concerns.
       - Maintainability and readability.
       - Security considerations.
       - Development effort.
       - Assign initial confidence score to each solution
  9. Analyze solutions by evaluating their pros/cons, risks, and potential impacts, and give a {Scoring Metric}. Include in the analysis "What could go wrong?".
  10. Present and justify the selection based on the comparison with a {Scoring Metric}.
  11. If the solution is not clear, ask for more information.

  Notes:
  - Scoring Metric ( ðŸ”´ for low, ðŸŸ¡ for medium, ðŸŸ¢ for high ):
    - Module Independence (1-5): Higher score = easier module change.
    - Clarity of Code (1-5): Higher score = code is easy to understand.
    - Component Reusability (1-5): Higher score = code is easily reused.
    - Test Coverage (1-5): Higher score = more code is tested.
  - Consider Visual Aids by adding diagrams (UML, flowcharts) to illustrate complex solutions.
</ProposeSolution>

<Retrospective>
Get all the logs and commit message from this project in an effcient manner (we want rich history of this project). 

Objective: Facilitate a retrospective discussion to evaluate past performance and propose improvements and follow these steps:

Output: Generate a detailed response addressing each step, providing clear and actionable insights based on retrospective principles.

  1. Start with Continuous Improvement:
     - Reflect on the overall iteration or project. What were the goals, and to what extent were they achieved? Identify key areas that could benefit from improvement.
  2. Analyze the Process:  
     - Evaluate workflows, systems, and processes used during the iteration. What aspects of the process worked well, and where were inefficiencies or bottlenecks observed?  
  3. Provide Constructive Feedback:  
     - Highlight the successes (what worked well) and challenges (what didn't work). Ensure the feedback is specific, actionable, and focused on the process, not individuals.  
  4. Define Action-Oriented Outcomes:  
     - Based on the identified challenges and successes, propose specific, measurable, and achievable action items that can improve the next iteration.  
  5. Reflect and Adapt:  
     - Reflect on lessons learned during this iteration. How can these insights be applied to adapt and improve the team's approach for future iterations?  
  6. Celebrate Successes:  
     - Acknowledge and celebrate the team's achievements. What were the highlights of this iteration that should be recognized and built upon?  
  7. Iterative Learning:  
     - Treat this session as part of a continuous learning cycle. How can the insights from this retrospective be incorporated into the team's ongoing improvement practices?  
</Retrospective>

<GenerateDocumentation>

# Role
You are an AI code assistant that generates brief yet context-rich documentation for code files.

# Objective
Your task is to analyze a given code file and generate a concise structured comment to be placed at the top.  

# Instructions:  
1. Keep the comment brief (max 5-7 lines) but informative.
2. Add a comments at the top of the file
3. Clearly summarize the fileâ€™s purpose in 1-2 sentences.  
4. List only the most important API endpoints (if applicable).  
5. Include key functions with their parameters and return types.  
6. Mention only critical dependencies (avoid unnecessary details).  
7. Format it cleanly for easy readability.  

# Example Output Format:  
```[Comments in native language]
FILE: [filename]
PURPOSE: [Short, precise summary of the fileâ€™s purpose]
API ENDPOINTS: (if applicable)  
  - [Method] [Endpoint] â†’ [Brief purpose]  
FUNCTIONS:  
  - [function_name]([parameters]) â†’ [return type]: [Short, precise summary of the function's purpose]
DEPENDENCIES: [List key external/internal dependencies]  
```
</GenerateDocumentation>

<GenerateCommit>
## Automating Git Commits for AI-Generated Codebases

### Overview
Automate Git commits for AI-generated code across platforms, triggering on test fail-to-pass transitions. Ensure stability and generate detailed Conventional Commit messages with "what" and "why" using terminal access (e.g., `git`, `npm`), adapting dynamically without config.

---

1. Detect Test Flip
- Goal: Trigger on test fail-to-pass.
- Steps: Check `package.json` `scripts.test` or infer runners (e.g., `jest`, `vitest`, `tuist test`). Monitor watch mode or last manual result for a flip; proceed if detected.
2. Verify Stability
- Goal: Ensure reliability.
- Steps: Confirm test flip. Run `npm run lint` and `tsc --noEmit` if present; skip if either fails. Check `git diff --cached` for untested breaking changes; skip if found. Log "Skipped: <reason>" (e.g., "Linting failed") and exit if unstable.
3. Stage Changes
- Goal: Prepare files.
- Steps: Run `git add .`, verify with `git status --short`.
4. Generate Message
- Goal: Craft detailed commit.
- Steps: Use `git diff --name-only --cached`, `--cached`, and test output to infer type (e.g., `feat`) and scope (e.g., `components`). Format: `<type>(<scope>): <subject>\n\n- What: <Change>\n- Why: <Reason>...`. Example:
  ```
  feat(components): Add new button

  - What: Added Button in src/components/button.js with size props.
  - Why: Enable dynamic size adjustments for a customizable UI.
  - What: Created tests in tests/button.test.js.
  - Why: Ensure reliable rendering and detect potential regressions.
  ```
5. Apply Guardrails
- Goal: Avoid noise.
- Steps: Skip if <5 lines or unrelated to test flip. Log "Skipped: <reason>" (e.g., "Trivial changes") and exit if fails; proceed if passes.
6. Commit
- Goal: Finalize with tag.
- Steps: Tag as `auto-MM-DD-YYYY-HHMM-AM/PM` (e.g., `auto-04-04-2025-0230-PM`). Run `git commit -m "<message>" --tag "<tag>"`.
7. Enable Undo
- Goal: Allow rollback.
- Steps: Log "Committed: <type>(<scope>): <subject> (undo: git undo-auto)". Support `git undo-auto` as `git reset --soft HEAD^`.
</GenerateCommit>




==========================
# Code Generation
==========================
- Focus on readability over being performant
- ALWAYS ensure minimal edits to existing logic
- ALWAYS indent the code blocks
- Always generate descriptive names

